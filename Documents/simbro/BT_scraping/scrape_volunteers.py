#!/usr/bin/env python3
"""
Scrape all volunteer program URLs and extract data into volunteer_frontend.json
Reads URLs from volunteer_urls.json (generated by get_volunteer_urls.py)
"""

from categorized_extractor import CategorizedTourExtractor
import json
import time
import os
import tempfile
import shutil
from datetime import datetime

def log_error(message):
    """Log errors to a dedicated error log file"""
    try:
        error_log = 'scraping_errors.log'
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        with open(error_log, 'a') as f:
            f.write(f"[{timestamp}] {message}\n")
    except Exception as e:
        print(f"‚ö†Ô∏è Could not write to error log: {e}")

def atomic_write_json(data, filename):
    """
    Write JSON data to file atomically to prevent corruption
    Returns (success: bool, error_message: str)
    """
    try:
        # Get the directory of the target file
        target_dir = os.path.dirname(os.path.abspath(filename)) if os.path.dirname(filename) else '.'

        # Create a temporary file in the same directory
        fd, temp_path = tempfile.mkstemp(suffix='.json', dir=target_dir, text=True)

        try:
            # Write JSON data to temp file
            with os.fdopen(fd, 'w') as f:
                json.dump(data, f, indent=2)

            # Atomically replace the old file with the new one
            shutil.move(temp_path, filename)

            # Set permissions to be readable by web server
            os.chmod(filename, 0o644)

            print(f"‚úÖ Successfully wrote: {filename}")
            return True, None

        except Exception as e:
            # Clean up temp file if write failed
            if os.path.exists(temp_path):
                os.unlink(temp_path)
            raise e

    except Exception as e:
        error_msg = f"Failed to write {filename}: {str(e)}"
        print(f"‚ùå {error_msg}")
        log_error(error_msg)
        return False, error_msg

def safe_remove_file(filepath):
    """
    Safely remove a file with error handling
    Returns (success: bool, error_message: str)
    """
    try:
        if os.path.exists(filepath):
            os.remove(filepath)
            print(f"üóëÔ∏è Removed: {filepath}")
            return True, None
        else:
            return True, "File does not exist"
    except Exception as e:
        error_msg = f"Could not remove {filepath}: {str(e)}"
        print(f"‚ö†Ô∏è {error_msg}")
        log_error(error_msg)
        return False, error_msg

def scrape_all_volunteers():
    """Scrape all volunteer programs from the JSON URL list"""

    # Load the URLs from JSON file
    try:
        with open('volunteer_urls.json', 'r') as f:
            url_data = json.load(f)

        # Extract just the bt_url values
        urls = [item['bt_url'] for item in url_data if item.get('bt_url')]

    except FileNotFoundError:
        print("‚ùå Error: volunteer_urls.json not found!")
        print("   Run get_volunteer_urls.py first to discover URLs")
        return []
    except Exception as e:
        print(f"‚ùå Error loading URLs from JSON: {e}")
        return []

    print(f"üöÄ Processing {len(urls)} volunteer program URLs...")
    print("=" * 70)

    extractor = CategorizedTourExtractor()
    all_program_data = []

    for i, url in enumerate(urls, 1):
        print(f"\n[{i}/{len(urls)}] {url.split('/')[-1]}")

        try:
            program_data = extractor.extract_tour_data(url)
            all_program_data.append(program_data)

            # Show progress
            program_name = program_data.get('tour_name', 'Unknown')
            dates_count = len(program_data.get('starting_dates', []))
            prices_count = sum(1 for v in program_data.get('price', {}).values() if v)

            print(f"  ‚úÖ {program_name}")
            print(f"     üìÖ {dates_count} dates | üí∞ {prices_count} currencies")

        except Exception as e:
            print(f"  ‚ùå Error: {e}")
            all_program_data.append({'url': url, 'error': str(e)})

        # Add delay between requests to be respectful
        time.sleep(2)

        # Save progress every 10 programs
        if i % 10 == 0:
            print(f"\nüíæ Saving progress after {i} programs...")
            with open(f'volunteer_progress_{i}.json', 'w') as f:
                json.dump(all_program_data, f, indent=2)

    # Save final results with timestamp
    import glob

    print(f"\nüíæ Saving final results...")

    # Add timestamp to the data and remove individual program timestamps to avoid conflicts
    timestamp = datetime.now().strftime('%Y-%m-%d')

    # Clean the program data by removing individual last_updated fields to avoid confusion
    cleaned_program_data = []
    for program in all_program_data:
        if isinstance(program, dict) and 'error' not in program:
            # Create a copy and remove any old last_updated field from individual programs
            clean_program = {k: v for k, v in program.items() if k != 'last_updated'}
            cleaned_program_data.append(clean_program)
        else:
            cleaned_program_data.append(program)

    final_data = {
        'last_updated': timestamp,
        'programs': cleaned_program_data
    }

    # Save with timestamp in filename for versioning
    timestamped_filename = f'volunteer_frontend_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'

    # Write main file using atomic write
    main_success, main_error = atomic_write_json(final_data, 'volunteer_frontend.json')
    if not main_success:
        error_msg = f"CRITICAL: Failed to save main file: {main_error}"
        print(f"‚ùå {error_msg}")
        log_error(error_msg)
        # Continue anyway to try timestamped backup

    # Write timestamped backup using atomic write
    backup_success, backup_error = atomic_write_json(final_data, timestamped_filename)
    if not backup_success:
        error_msg = f"WARNING: Failed to save backup file: {backup_error}"
        print(f"‚ö†Ô∏è {error_msg}")
        log_error(error_msg)

    # Only report success if at least one file was written
    if main_success or backup_success:
        if main_success:
            print(f"üìÅ Saved main file: volunteer_frontend.json")
        if backup_success:
            print(f"üìÅ Saved timestamped file: {timestamped_filename}")
    else:
        error_msg = "CRITICAL: Failed to save both main and backup files!"
        print(f"‚ùå {error_msg}")
        log_error(error_msg)
        return all_program_data  # Return early if all writes failed

    # Cleanup operations after successful scraping
    print(f"\nüßπ Cleaning up old files...")

    # Remove progress files from this run
    progress_files = glob.glob('volunteer_progress_*.json')
    for progress_file in progress_files:
        safe_remove_file(progress_file)

    # Remove backup files older than 7 days
    current_time = time.time()
    for backup_file in glob.glob('volunteer_frontend_backup_*.json'):
        try:
            file_age = current_time - os.path.getmtime(backup_file)
            if file_age > 7 * 24 * 3600:  # 7 days in seconds
                safe_remove_file(backup_file)
        except Exception as e:
            print(f"‚ö†Ô∏è Could not check age of {backup_file}: {e}")

    # Remove timestamped files older than 3 days (keep some for backup)
    for timestamped_file in glob.glob('volunteer_frontend_2*.json'):
        if timestamped_file != timestamped_filename:  # Don't remove the one we just created
            try:
                file_age = current_time - os.path.getmtime(timestamped_file)
                if file_age > 3 * 24 * 3600:  # 3 days in seconds
                    safe_remove_file(timestamped_file)
            except Exception as e:
                print(f"‚ö†Ô∏è Could not check age of {timestamped_file}: {e}")

    print(f"‚úÖ Cleanup completed")

    # Summary
    successful = len([p for p in all_program_data if 'error' not in p])
    failed = len(all_program_data) - successful

    print(f"\nüéâ EXTRACTION COMPLETE!")
    print(f"   ‚úÖ Successfully processed: {successful} programs")
    print(f"   ‚ùå Failed: {failed} programs")
    print(f"   üìÅ Results saved to: volunteer_frontend.json")

    # Show sample of program names extracted
    print(f"\nüè∑Ô∏è  Sample program names extracted:")
    for i, program in enumerate(all_program_data[:5], 1):
        if 'error' not in program:
            name = program.get('tour_name', 'Unknown')
            print(f"   {i}. {name}")

    return all_program_data

if __name__ == "__main__":
    scrape_all_volunteers()
