name: Daily Tour Data Scraping

on:
  schedule:
    # Run daily at 3 AM UTC (10 AM Thailand time)
    - cron: '0 3 * * *'
  workflow_dispatch:  # Allow manual trigger

jobs:
  scrape-tours:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run URL discovery
      run: |
        echo "ðŸ” Discovering tour URLs..."
        python get_grouptour_urls.py

    - name: Run tour scraping
      run: |
        echo "ðŸ•·ï¸ Scraping tour data..."
        python scrape_grouptours.py

    - name: Merge CSV data (available spaces and prices)
      env:
        GITHUB_TOKEN: ${{ secrets.TOURISM_API_TOKEN }}
      run: |
        echo "ðŸ“Š Merging CSV data for available spaces and global prices..."
        python merge_csv_data.py

    - name: Check for changes
      id: verify-changed-files
      run: |
        if [ -n "$(git status --porcelain)" ]; then
          echo "changed=true" >> $GITHUB_OUTPUT
        else
          echo "changed=false" >> $GITHUB_OUTPUT
        fi

    - name: Commit and push changes
      if: steps.verify-changed-files.outputs.changed == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add group_tour_urls.json group_tours_frontend.json group_tours_frontend_enhanced.json
        git commit -m "ðŸ¤– Daily tour data update - $(date +'%Y-%m-%d %H:%M UTC')"
        git push

    - name: Deploy to simbro.app server
      env:
        SERVER_PASSWORD: ${{ secrets.SERVER_PASSWORD }}
      run: |
        echo "ðŸš€ Deploying updated files to simbro.app..."
        sudo apt-get update && sudo apt-get install -y sshpass
        sshpass -p "$SERVER_PASSWORD" scp -o StrictHostKeyChecking=no \
          group_tours_frontend_enhanced.json \
          root@72.60.107.156:/var/www/html/BT_scraping/
        echo "âœ… Deployed enhanced JSON to server"

    - name: Summary
      run: |
        echo "âœ… Daily scraping completed!"
        if [ -f "group_tours_frontend.json" ]; then
          tour_count=$(python -c "import json; data=json.load(open('group_tours_frontend.json')); tours=data if isinstance(data, list) else data.get('tours', []); print(len(tours))")
          echo "ðŸ“Š Successfully scraped: $tour_count tours"
        fi
